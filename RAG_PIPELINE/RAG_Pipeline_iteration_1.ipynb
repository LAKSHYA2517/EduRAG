{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b5c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Imports and Environment Setup ---\n",
    "import os\n",
    "import re\n",
    "import base64\n",
    "import io\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader, CSVLoader, UnstructuredExcelLoader, UnstructuredPowerPointLoader\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Dict\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import tool\n",
    "from langchain import hub\n",
    "# ⬇️ ADDED: Imports for the new Python Math Solver tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86087535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9493bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2: Configuration ---\n",
    "DOCS_PATH = \"./documents\"\n",
    "CHROMA_PERSIST_PATH = \"./chroma_db\"\n",
    "EMBEDDING_MODEL = 'BAAI/bge-base-en-v1.5'\n",
    "CROSS_ENCODER_MODEL = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "LLM_MODEL = \"gemini-1.5-flash-latest\" \n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e89f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Helper Functions (Document Processors & Vector Store Setup) ---\n",
    "\n",
    "def get_image_summary(image_bytes: bytes, llm: ChatGoogleGenerativeAI) -> str:\n",
    "    \"\"\"Generates a summary for an image using a multi-modal LLM.\"\"\"\n",
    "    print(\"Generating image summary...\")\n",
    "    prompt_messages = [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"You are an expert at analyzing academic images, diagrams, and charts. Describe this image in detail. What is its main purpose? What key information does it convey? If it's a chart or graph, describe the data, axes, and trend. This summary will be used for a Retrieval-Augmented Generation (RAG) system, so be comprehensive.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base64.b64encode(image_bytes).decode()}\"}\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    try:\n",
    "        response = llm.invoke(prompt_messages)\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating image summary: {e}\")\n",
    "        return \"Could not generate summary for this image.\"\n",
    "\n",
    "class SmartPDFProcessor:\n",
    "    # ⬇️ MODIFIED: Reverted from Nougat to PyPDFLoader for broader compatibility and to remove the dependency.\n",
    "    def __init__(self, embeddings, llm=None):\n",
    "        self.text_splitter = SemanticChunker(embeddings)\n",
    "        self.llm = llm\n",
    "    def process_pdf(self, pdf_path: str) -> List[Document]:\n",
    "        print(f\"Processing PDF with PyPDFLoader: {pdf_path}\")\n",
    "        all_docs = []\n",
    "        try:\n",
    "            # --- Standard Text Extraction ---\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            pages = loader.load()\n",
    "            \n",
    "            full_text = \"\\n\\n\".join([self._clean_text(page.page_content) for page in pages])\n",
    "            chunks = self.text_splitter.create_documents([full_text])\n",
    "            for chunk in chunks: chunk.metadata['source'] = pdf_path\n",
    "            all_docs.extend(chunks)\n",
    "\n",
    "            # --- Image Extraction and Summarization ---\n",
    "            if self.llm:\n",
    "                pdf_document = fitz.open(pdf_path)\n",
    "                for page_num in range(len(pdf_document)):\n",
    "                    for img_index, img in enumerate(pdf_document.get_page_images(page_num)):\n",
    "                        xref, base_image = img[0], pdf_document.extract_image(img[0])\n",
    "                        summary = get_image_summary(base_image[\"image\"], self.llm)\n",
    "                        all_docs.append(Document(page_content=summary, metadata={ \"source\": pdf_path, \"page\": page_num + 1, \"chunk_method\": \"pdf_image_summary\", \"image_index\": img_index }))\n",
    "            print(f\"✅ Successfully processed {len(all_docs)} chunks and summaries from {pdf_path}\")\n",
    "            return all_docs\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {pdf_path}: {e}\"); return []\n",
    "    def _clean_text(self, text: str) -> str: return re.sub(r'\\s+', ' ', text).strip().replace(\"ﬁ\", \"fi\").replace(\"ﬂ\", \"fl\")\n",
    "\n",
    "class SmartDocProcessor:\n",
    "    def __init__(self, embeddings): self.text_splitter = SemanticChunker(embeddings)\n",
    "    def process_document(self, doc_path: str) -> List[Document]:\n",
    "        print(f\"Processing document: {doc_path}\")\n",
    "        try:\n",
    "            if doc_path.lower().endswith(\".docx\"): loader = Docx2txtLoader(doc_path)\n",
    "            elif doc_path.lower().endswith(\".txt\"): loader = TextLoader(doc_path, encoding='utf-8')\n",
    "            else: return []\n",
    "            documents = loader.load()\n",
    "            full_text = \"\\n\\n\".join([self._clean_text(doc.page_content) for doc in documents if len(self._clean_text(doc.page_content).strip()) >= 50])\n",
    "            if not full_text: return []\n",
    "            splits = self.text_splitter.create_documents([full_text])\n",
    "            for split in splits: split.metadata.update({ \"source\": doc_path, \"chunk_method\": \"semantic_chunker_text\", \"char_count\": len(split.page_content)})\n",
    "            print(f\"✅ Successfully processed {len(splits)} chunks from {doc_path}\")\n",
    "            return splits\n",
    "        except Exception as e: print(f\"❌ Error processing {doc_path}: {e}\"); return []\n",
    "    def _clean_text(self, text: str) -> str: return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "class SmartLatexProcessor:\n",
    "    def __init__(self, embeddings): self.text_splitter = SemanticChunker(embeddings)\n",
    "    def process_latex(self, tex_path: str) -> List[Document]:\n",
    "        print(f\"Processing LaTeX file: {tex_path}\")\n",
    "        try:\n",
    "            loader = TextLoader(tex_path, encoding='utf-8')\n",
    "            documents = loader.load()\n",
    "            full_text, cleaned_text = \"\\n\".join([doc.page_content for doc in documents]), self._clean_latex(full_text)\n",
    "            if len(cleaned_text.strip()) < 100: return []\n",
    "            splits = self.text_splitter.create_documents([cleaned_text])\n",
    "            for split in splits: split.metadata.update({ \"source\": tex_path, \"chunk_method\": \"semantic_chunker_latex\", \"char_count\": len(split.page_content)})\n",
    "            print(f\"✅ Successfully processed {len(splits)} chunks from {tex_path}\"); return splits\n",
    "        except Exception as e: print(f\"❌ Error processing {tex_path}: {e}\"); return []\n",
    "    def _clean_latex(self, text: str) -> str:\n",
    "        if \"\\\\begin{document}\" in text: text = text.split(\"\\\\begin{document}\")[1]\n",
    "        text = re.sub(r\"%.*?\\n\", \"\\n\", text)\n",
    "        text = re.sub(r\"\\\\begin\\{(?:figure|table|tabular|verbatim|lstlisting)\\*?\\}[\\s\\S]*?\\\\end\\{(?:figure|table|tabular|verbatim|lstlisting)\\*?\\}\", \"\", text, flags=re.MULTILINE)\n",
    "        text = re.sub(r\"\\\\documentclass(?:\\[.*?\\])?\\{.*?\\}|\\\\usepackage(?:\\[.*?\\])?\\{.*?\\}|\\\\(title|author|date|thanks)\\{.*?\\}\", \"\", text, flags=re.DOTALL)\n",
    "        text = re.sub(r\"\\\\(maketitle|tableofcontents|listoffigures|listoftables|centering|newpage|section\\*|subsection\\*|subsubsection\\*)\\b|\\\\(begin|end)\\{.*?\\}\", \"\", text)\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "class SmartSheetProcessor:\n",
    "    def process_sheet(self, sheet_path: str) -> List[Document]:\n",
    "        try:\n",
    "            if sheet_path.lower().endswith(\".csv\"): loader = CSVLoader(file_path=sheet_path, encoding='utf-8')\n",
    "            elif sheet_path.lower().endswith(\".xlsx\"): loader = UnstructuredExcelLoader(sheet_path, mode=\"elements\")\n",
    "            else: return []\n",
    "            return loader.load()\n",
    "        except Exception as e: print(f\"❌ Error processing {sheet_path}: {e}\"); return []\n",
    "\n",
    "class SmartPPTProcessor:\n",
    "    def process_ppt(self, ppt_path: str) -> List[Document]:\n",
    "        try: loader = UnstructuredPowerPointLoader(ppt_path, mode=\"elements\"); return loader.load()\n",
    "        except Exception as e: print(f\"❌ Error processing {ppt_path}: {e}\"); return []\n",
    "\n",
    "def process_all_documents(embedding_function, llm_for_summaries) -> List[Document]:\n",
    "    all_splits, processors = [], {\".pdf\": SmartPDFProcessor(embeddings=embedding_function, llm=llm_for_summaries), \".txt\": SmartDocProcessor(embeddings=embedding_function), \".docx\": SmartDocProcessor(embeddings=embedding_function), \".tex\": SmartLatexProcessor(embeddings=embedding_function), \".csv\": SmartSheetProcessor(), \".xlsx\": SmartSheetProcessor(), \".pptx\": SmartPPTProcessor(), \".ppt\": SmartPPTProcessor()}\n",
    "    for filename in os.listdir(DOCS_PATH):\n",
    "        file_path, file_ext = os.path.join(DOCS_PATH, filename), os.path.splitext(filename)[1].lower()\n",
    "        if file_ext in processors:\n",
    "            processor = processors[file_ext]\n",
    "            if hasattr(processor, 'process_pdf'): all_splits.extend(processor.process_pdf(file_path))\n",
    "            elif hasattr(processor, 'process_document'): all_splits.extend(processor.process_document(file_path))\n",
    "            elif hasattr(processor, 'process_latex'): all_splits.extend(processor.process_latex(file_path))\n",
    "            elif hasattr(processor, 'process_sheet'): all_splits.extend(processor.process_sheet(file_path))\n",
    "            elif hasattr(processor, 'process_ppt'): all_splits.extend(processor.process_ppt(file_path))\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 4: RAG Chain and Tool Creation ---\n",
    "def create_rag_chain(retriever, llm):\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages([(\"system\", \"Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"), MessagesPlaceholder(\"chat_history\"), (\"human\", \"{input}\")])\n",
    "    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n",
    "    qa_system_prompt = (\"You are an expert AI Curriculum Assistant. Your task is to answer user questions accurately and concisely based ONLY on the provided context. This context contains text excerpts and detailed summaries of images, charts, or diagrams. When referencing visual content, explicitly mention it (e.g., 'As seen in the diagram...'). If the context does not contain the answer, state that you cannot find the information in the provided materials. Do not use any external knowledge.\\n\\nContext:\\n{context}\")\n",
    "    qa_prompt = ChatPromptTemplate.from_messages([(\"system\", qa_system_prompt), MessagesPlaceholder(\"chat_history\"), (\"human\", \"{input}\")])\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "    return create_retrieval_chain(history_aware_retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5: Assistant Tools and Features ---\n",
    "# Global variables to hold initialized components for the tools\n",
    "progress_tracker: Dict[str, str] = {}\n",
    "llm = None\n",
    "retriever = None\n",
    "all_documents_for_tools = []\n",
    "python_repl_tool = None\n",
    "# ⬇️ MODIFIED: Added rag_chain_for_tools to the global scope to fix the undefined variable error\n",
    "rag_chain_for_tools = None\n",
    "\n",
    "@tool\n",
    "def curriculum_qa_tool(input: str, chat_history: List = []):\n",
    "    \"\"\"\n",
    "    Use this tool to answer any question about the content of the uploaded curriculum documents.\n",
    "    It is the primary tool for factual questions and information retrieval from the knowledge base.\n",
    "    For example: 'What is photosynthesis?', 'Summarize the section on data structures.'\n",
    "    \"\"\"\n",
    "    if rag_chain_for_tools is None: return \"RAG chain not initialized.\"\n",
    "    response = rag_chain_for_tools.invoke({\"input\": input, \"chat_history\": chat_history})\n",
    "    return response['answer']\n",
    "\n",
    "# ⬇️ ADDED: A new tool for solving mathematical problems agentically\n",
    "@tool\n",
    "def python_math_solver(problem: str):\n",
    "    \"\"\"\n",
    "    Use this specialized tool to solve mathematical problems, perform calculations, or answer word problems that require logic and computation.\n",
    "    It works by writing and executing Python code. For example: 'What is 24 * 5?', 'If a car travels at 80 km/h for 2.5 hours, how far does it go?'.\n",
    "    \"\"\"\n",
    "    if not llm or not python_repl_tool: return \"Math solver components not initialized.\"\n",
    "    print(f\"--- 🐍 Solving math problem with Python: '{problem}' ---\")\n",
    "\n",
    "    # A specific prompt to instruct the LLM to generate only Python code\n",
    "    code_gen_prompt_text = (\n",
    "        \"You are an expert Python programmer tasked with solving a mathematical problem. \"\n",
    "        \"Based on the user's problem, write a single, executable block of Python code to find the solution. \"\n",
    "        \"IMPORTANT:\\n\"\n",
    "        \"- Only output the Python code. Do not include any explanation, comments, or markdown formatting like ```python. \"\n",
    "        \"- The code MUST print the final answer to the console using the print() function. \"\n",
    "        \"- You can use standard libraries like 'math'.\\n\\n\"\n",
    "        \"Problem: {problem}\"\n",
    "    )\n",
    "    code_gen_prompt = ChatPromptTemplate.from_template(code_gen_prompt_text)\n",
    "    \n",
    "    # Create a chain to generate the code\n",
    "    code_gen_chain = code_gen_prompt | llm\n",
    "    \n",
    "    # Generate the code string\n",
    "    code_to_execute = code_gen_chain.invoke({\"problem\": problem}).content\n",
    "\n",
    "    # Execute the code and return the result\n",
    "    try:\n",
    "        result = python_repl_tool.run(code_to_execute)\n",
    "        return f\"Solution:\\n{result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error executing the Python code: {e}\"\n",
    "\n",
    "@tool\n",
    "def enhanced_quiz_generator(topic: str, num_questions: int = 3, question_type: str = \"multiple choice\"):\n",
    "    \"\"\"\n",
    "    Generates a quiz on a specific topic based on the curriculum. \n",
    "    Use this when the user explicitly asks for a quiz, test, or to check their knowledge.\n",
    "    Arguments: topic (str), num_questions (int, default 3), question_type (str, default 'multiple choice').\n",
    "    \"\"\"\n",
    "    if not retriever or not llm: return \"Retriever or LLM not initialized.\"\n",
    "    print(f\"--- ❓ Generating a {num_questions}-question quiz on '{topic}'... ---\")\n",
    "    context_docs = retriever.invoke(topic)\n",
    "    context_text = \"\\n\\n\".join([doc.page_content for doc in context_docs])\n",
    "    if not context_text.strip(): return f\"Sorry, I couldn't find enough information on '{topic}' to create a quiz.\"\n",
    "    \n",
    "    quiz_prompt_text = (\n",
    "        \"You are an expert quiz creator. Based ONLY on the provided context, create a quiz with {num_questions} \"\n",
    "        \"{question_type} questions about '{topic}'. For each multiple-choice question, provide 4 options (A, B, C, D) \"\n",
    "        \"and clearly mark the correct answer. For other question types, provide the question and the correct answer based on the text.\\n\\n\"\n",
    "        \"Context:\\n---\\n{context}\\n---\"\n",
    "    )\n",
    "    quiz_prompt = ChatPromptTemplate.from_template(quiz_prompt_text)\n",
    "    quiz_chain = quiz_prompt | llm\n",
    "    response = quiz_chain.invoke({\"num_questions\": num_questions, \"topic\": topic, \"question_type\": question_type, \"context\": context_text})\n",
    "    return response.content\n",
    "\n",
    "@tool\n",
    "def learning_path_suggester(topic: str):\n",
    "    \"\"\"\n",
    "    Suggests a step-by-step learning path for a given topic based on the provided documents.\n",
    "    Use this when the user asks 'How should I study for X?', 'What's the learning path for Y?', or 'Suggest a study plan.'\n",
    "    \"\"\"\n",
    "    if not llm: return \"LLM not initialized.\"\n",
    "    print(f\"--- 🗺️ Generating a learning path for '{topic}'... ---\")\n",
    "    full_context = \"\\n\\n\".join([doc.page_content for doc in all_documents_for_tools])\n",
    "    path_prompt_text = (\n",
    "        \"You are an expert academic advisor. Based on the entire curriculum provided, analyze the content related to '{topic}'. \"\n",
    "        \"Create a logical, step-by-step learning path for a student to master this topic. Break it down into key concepts, \"\n",
    "        \"suggesting the order in which they should be studied. Your output should be a clear, actionable list.\\n\\n\"\n",
    "        \"Full Curriculum Context:\\n---\\n{context}\\n---\"\n",
    "    )\n",
    "    path_prompt = ChatPromptTemplate.from_template(path_prompt_text)\n",
    "    path_chain = path_prompt | llm\n",
    "    response = path_chain.invoke({\"topic\": topic, \"context\": full_context})\n",
    "    return response.content\n",
    "\n",
    "@tool\n",
    "def mark_topic_as_studied(topic: str):\n",
    "    \"\"\"\n",
    "    Marks a topic as 'studied' in the progress tracker. Use this when a user says they have finished studying a topic.\n",
    "    \"\"\"\n",
    "    print(f\"--- ✅ Marking '{topic}' as studied. ---\")\n",
    "    progress_tracker[topic.lower()] = \"Studied\"\n",
    "    return f\"Great! I've marked '{topic}' as studied. Keep up the great work!\"\n",
    "\n",
    "@tool\n",
    "def view_study_progress(input: str = \"\"):\n",
    "    \"\"\"\n",
    "    Shows the user's study progress. Use this when the user asks 'What have I studied?' or 'Show my progress.'\n",
    "    This tool takes no arguments.\n",
    "    \"\"\"\n",
    "    print(\"--- 📊 Displaying study progress... ---\")\n",
    "    if not progress_tracker:\n",
    "        return \"You haven't marked any topics as studied yet.\"\n",
    "    progress_report = \"Here's your study progress so far:\\n\"\n",
    "    for topic, status in progress_tracker.items():\n",
    "        progress_report += f\"- {topic.capitalize()}: {status}\\n\"\n",
    "    return progress_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cdf795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 6: Initialization and Main Execution ---\n",
    "print(\"--- 🚀 AI Curriculum Assistant Initializing (Agent Mode) 🚀 ---\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"❌ Error: GOOGLE_API_KEY not found. Please set it in your .env file.\")\n",
    "else:\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "        llm = ChatGoogleGenerativeAI(model=LLM_MODEL, google_api_key=GOOGLE_API_KEY, temperature=0.5)\n",
    "        \n",
    "        all_documents_for_tools = process_all_documents(embeddings, llm)\n",
    "        if not all_documents_for_tools: raise ValueError(\"No documents processed. Halting initialization.\")\n",
    "\n",
    "        vectorstore = Chroma.from_documents(documents=all_documents_for_tools, embedding=embeddings)\n",
    "        vector_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "        bm25_retriever = BM25Retriever.from_documents(all_documents_for_tools, k=10)\n",
    "        ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, vector_retriever], weights=[0.5, 0.5])\n",
    "        \n",
    "        cross_encoder = CrossEncoder(CROSS_ENCODER_MODEL)\n",
    "        compressor = CrossEncoderReranker(model=cross_encoder, top_n=3)\n",
    "        retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)\n",
    "        \n",
    "        rag_chain_for_tools = create_rag_chain(retriever, llm)\n",
    "        python_repl_tool = PythonREPLTool() # Initialize the Python REPL\n",
    "        \n",
    "        # ⬇️ MODIFIED: Added the new math solver tool to the agent's toolkit\n",
    "        tools = [curriculum_qa_tool, python_math_solver, enhanced_quiz_generator, learning_path_suggester, mark_topic_as_studied, view_study_progress]\n",
    "        \n",
    "        agent_prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "        agent = create_react_agent(llm, tools, agent_prompt)\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "        \n",
    "        chat_history = []\n",
    "        print(\"\\n✅ Multi-tool Assistant is ready! Ask me a curriculum question or give me a math problem to solve.\")\n",
    "        \n",
    "    except ValueError as e: print(f\"❌ Error: {e}\")\n",
    "    except Exception as e: print(f\"❌ An unexpected error occurred during initialization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 7: Interactive Chat Loop ---\n",
    "if 'agent_executor' in locals():\n",
    "    # ⬇️ MODIFIED: Example input changed to demonstrate the new math solver tool\n",
    "    user_input = \"If a box measures 2m in length, 3m in width, and 1.5m in height, what is its volume in cubic meters?\"\n",
    "    \n",
    "    response = agent_executor.invoke({\n",
    "        \"input\": user_input,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    \n",
    "    answer = response[\"output\"]\n",
    "    print(f\"🤖 Assistant: {answer}\")\n",
    "    \n",
    "    chat_history.extend([\n",
    "        HumanMessage(content=user_input),\n",
    "        AIMessage(content=answer),\n",
    "    ])\n",
    "else:\n",
    "    print(\"The Agent Executor is not initialized. Please run the setup cells successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
