{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b5c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Imports and Environment Setup ---\n",
    "import os\n",
    "import re\n",
    "import base64\n",
    "import io\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader, CSVLoader, UnstructuredExcelLoader, UnstructuredPowerPointLoader\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Dict\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "# â¬‡ï¸ MODIFIED: The reranker class now needs its specific import\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import tool\n",
    "from langchain import hub\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8014cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('./documents', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9493bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c55f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2: Configuration ---\n",
    "DOCS_PATH = \"./documents\"\n",
    "CHROMA_PERSIST_PATH = \"./chroma_db\"\n",
    "# â¬‡ï¸ MODIFIED: This variable now MANDATES a single file to be processed.\n",
    "# The script will raise an error if this is empty or the file is not found.\n",
    "PROCESS_SPECIFIC_FILE = \"DataStructures.pdf\" # Example: \"DataStructures.pdf\"\n",
    "\n",
    "EMBEDDING_MODEL = 'BAAI/bge-base-en-v1.5'\n",
    "CROSS_ENCODER_MODEL = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "LLM_MODEL = \"gemini-1.5-flash-latest\" \n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e89f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Helper Functions (Document Processors & Vector Store Setup) ---\n",
    "\n",
    "def get_image_summary(image_bytes: bytes, llm: ChatGoogleGenerativeAI) -> str:\n",
    "    \"\"\"Generates a summary for an image using a multi-modal LLM.\"\"\"\n",
    "    print(\"Generating image summary...\")\n",
    "    prompt_messages = [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"You are an expert at analyzing academic images, diagrams, and charts. Describe this image in detail. What is its main purpose? What key information does it convey? If it's a chart or graph, describe the data, axes, and trend. This summary will be used for a Retrieval-Augmented Generation (RAG) system, so be comprehensive.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base64.b64encode(image_bytes).decode()}\"}\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    try:\n",
    "        response = llm.invoke(prompt_messages)\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating image summary: {e}\")\n",
    "        return \"Could not generate summary for this image.\"\n",
    "\n",
    "class SmartPDFProcessor:\n",
    "    def __init__(self, embeddings, llm=None):\n",
    "        self.text_splitter = SemanticChunker(embeddings)\n",
    "        self.llm = llm\n",
    "    def process_pdf(self, pdf_path: str) -> List[Document]:\n",
    "        print(f\"Processing PDF with PyPDFLoader: {pdf_path}\")\n",
    "        all_docs = []\n",
    "        try:\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            pages = loader.load()\n",
    "            \n",
    "            full_text = \"\\n\\n\".join([self._clean_text(page.page_content) for page in pages])\n",
    "            chunks = self.text_splitter.create_documents([full_text])\n",
    "            for chunk in chunks: chunk.metadata['source'] = pdf_path\n",
    "            all_docs.extend(chunks)\n",
    "\n",
    "            if self.llm:\n",
    "                pdf_document = fitz.open(pdf_path)\n",
    "                for page_num in range(len(pdf_document)):\n",
    "                    for img_index, img in enumerate(pdf_document.get_page_images(page_num)):\n",
    "                        xref, base_image = img[0], pdf_document.extract_image(img[0])\n",
    "                        summary = get_image_summary(base_image[\"image\"], self.llm)\n",
    "                        all_docs.append(Document(page_content=summary, metadata={ \"source\": pdf_path, \"page\": page_num + 1, \"chunk_method\": \"pdf_image_summary\", \"image_index\": img_index }))\n",
    "            print(f\"âœ… Successfully processed {len(all_docs)} chunks and summaries from {pdf_path}\")\n",
    "            return all_docs\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {pdf_path}: {e}\"); return []\n",
    "    def _clean_text(self, text: str) -> str: return re.sub(r'\\s+', ' ', text).strip().replace(\"ï¬\", \"fi\").replace(\"ï¬‚\", \"fl\")\n",
    "\n",
    "class SmartDocProcessor:\n",
    "    def __init__(self, embeddings): self.text_splitter = SemanticChunker(embeddings)\n",
    "    def process_document(self, doc_path: str) -> List[Document]:\n",
    "        print(f\"Processing document: {doc_path}\")\n",
    "        try:\n",
    "            if doc_path.lower().endswith(\".docx\"): loader = Docx2txtLoader(doc_path)\n",
    "            elif doc_path.lower().endswith(\".txt\"): loader = TextLoader(doc_path, encoding='utf-8')\n",
    "            else: return []\n",
    "            documents = loader.load()\n",
    "            full_text = \"\\n\\n\".join([self._clean_text(doc.page_content) for doc in documents if len(self._clean_text(doc.page_content).strip()) >= 50])\n",
    "            if not full_text: return []\n",
    "            splits = self.text_splitter.create_documents([full_text])\n",
    "            for split in splits: split.metadata.update({ \"source\": doc_path, \"chunk_method\": \"semantic_chunker_text\", \"char_count\": len(split.page_content)})\n",
    "            print(f\"âœ… Successfully processed {len(splits)} chunks from {doc_path}\")\n",
    "            return splits\n",
    "        except Exception as e: print(f\"âŒ Error processing {doc_path}: {e}\"); return []\n",
    "    def _clean_text(self, text: str) -> str: return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "class SmartLatexProcessor:\n",
    "    def __init__(self, embeddings): self.text_splitter = SemanticChunker(embeddings)\n",
    "    def process_latex(self, tex_path: str) -> List[Document]:\n",
    "        print(f\"Processing LaTeX file: {tex_path}\")\n",
    "        try:\n",
    "            loader = TextLoader(tex_path, encoding='utf-8')\n",
    "            documents = loader.load()\n",
    "            full_text, cleaned_text = \"\\n\".join([doc.page_content for doc in documents]), self._clean_latex(full_text)\n",
    "            if len(cleaned_text.strip()) < 100: return []\n",
    "            splits = self.text_splitter.create_documents([cleaned_text])\n",
    "            for split in splits: split.metadata.update({ \"source\": tex_path, \"chunk_method\": \"semantic_chunker_latex\", \"char_count\": len(split.page_content)})\n",
    "            print(f\"âœ… Successfully processed {len(splits)} chunks from {tex_path}\"); return splits\n",
    "        except Exception as e: print(f\"âŒ Error processing {tex_path}: {e}\"); return []\n",
    "    def _clean_latex(self, text: str) -> str:\n",
    "        if \"\\\\begin{document}\" in text: text = text.split(\"\\\\begin{document}\")[1]\n",
    "        text = re.sub(r\"%.*?\\n\", \"\\n\", text)\n",
    "        text = re.sub(r\"\\\\begin\\{(?:figure|table|tabular|verbatim|lstlisting)\\*?\\}[\\s\\S]*?\\\\end\\{(?:figure|table|tabular|verbatim|lstlisting)\\*?\\}\", \"\", text, flags=re.MULTILINE)\n",
    "        text = re.sub(r\"\\\\documentclass(?:\\[.*?\\])?\\{.*?\\}|\\\\usepackage(?:\\[.*?\\])?\\{.*?\\}|\\\\(title|author|date|thanks)\\{.*?\\}\", \"\", text, flags=re.DOTALL)\n",
    "        text = re.sub(r\"\\\\(maketitle|tableofcontents|listoffigures|listoftables|centering|newpage|section\\*|subsection\\*|subsubsection\\*)\\b|\\\\(begin|end)\\{.*?\\}\", \"\", text)\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "class SmartSheetProcessor:\n",
    "    def process_sheet(self, sheet_path: str) -> List[Document]:\n",
    "        try:\n",
    "            if sheet_path.lower().endswith(\".csv\"): loader = CSVLoader(file_path=sheet_path, encoding='utf-8')\n",
    "            elif sheet_path.lower().endswith(\".xlsx\"): loader = UnstructuredExcelLoader(sheet_path, mode=\"elements\")\n",
    "            else: return []\n",
    "            return loader.load()\n",
    "        except Exception as e: print(f\"âŒ Error processing {sheet_path}: {e}\"); return []\n",
    "\n",
    "class SmartPPTProcessor:\n",
    "    def process_ppt(self, ppt_path: str) -> List[Document]:\n",
    "        try: loader = UnstructuredPowerPointLoader(ppt_path, mode=\"elements\"); return loader.load()\n",
    "        except Exception as e: print(f\"âŒ Error processing {ppt_path}: {e}\"); return []\n",
    "\n",
    "# â¬‡ï¸ MODIFIED: This function is now simplified to only process one specified file.\n",
    "def process_single_file(embedding_function, llm_for_summaries) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Processes a single file specified by the PROCESS_SPECIFIC_FILE variable.\n",
    "    \"\"\"\n",
    "    if not PROCESS_SPECIFIC_FILE:\n",
    "        raise ValueError(\"The 'PROCESS_SPECIFIC_FILE' variable is not set. Please specify a filename in Cell 2.\")\n",
    "\n",
    "    specific_file_path = os.path.join(DOCS_PATH, PROCESS_SPECIFIC_FILE)\n",
    "    \n",
    "    if not os.path.exists(specific_file_path):\n",
    "        raise FileNotFoundError(f\"The specified file '{PROCESS_SPECIFIC_FILE}' was not found in the '{DOCS_PATH}' directory.\")\n",
    "\n",
    "    print(f\"--- ðŸŽ¯ Processing specific file: {PROCESS_SPECIFIC_FILE} ---\")\n",
    "    \n",
    "    all_splits, processors = [], {\".pdf\": SmartPDFProcessor(embeddings=embedding_function, llm=llm_for_summaries), \".txt\": SmartDocProcessor(embeddings=embedding_function), \".docx\": SmartDocProcessor(embeddings=embedding_function), \".tex\": SmartLatexProcessor(embeddings=embedding_function), \".csv\": SmartSheetProcessor(), \".xlsx\": SmartSheetProcessor(), \".pptx\": SmartPPTProcessor(), \".ppt\": SmartPPTProcessor()}\n",
    "    \n",
    "    filename = PROCESS_SPECIFIC_FILE\n",
    "    file_path, file_ext = os.path.join(DOCS_PATH, filename), os.path.splitext(filename)[1].lower()\n",
    "    \n",
    "    if file_ext in processors:\n",
    "        processor = processors[file_ext]\n",
    "        if hasattr(processor, 'process_pdf'): all_splits.extend(processor.process_pdf(file_path))\n",
    "        elif hasattr(processor, 'process_document'): all_splits.extend(processor.process_document(file_path))\n",
    "        elif hasattr(processor, 'process_latex'): all_splits.extend(processor.process_latex(file_path))\n",
    "        elif hasattr(processor, 'process_sheet'): all_splits.extend(processor.process_sheet(file_path))\n",
    "        elif hasattr(processor, 'process_ppt'): all_splits.extend(processor.process_ppt(file_path))\n",
    "    else:\n",
    "        print(f\"âŒ Warning: File type '{file_ext}' for file '{filename}' is not supported.\")\n",
    "\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44e9b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 4: RAG Chain and Tool Creation ---\n",
    "def create_rag_chain(retriever, llm):\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages([(\"system\", \"Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"), MessagesPlaceholder(\"chat_history\"), (\"human\", \"{input}\")])\n",
    "    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n",
    "    qa_system_prompt = (\"You are an expert AI Curriculum Assistant. Your task is to answer user questions accurately and concisely based ONLY on the provided context. This context contains text excerpts and detailed summaries of images, charts, or diagrams. When referencing visual content, explicitly mention it (e.g., 'As seen in the diagram...'). If the context does not contain the answer, state that you cannot find the information in the provided materials. Do not use any external knowledge.\\n\\nContext:\\n{context}\")\n",
    "    qa_prompt = ChatPromptTemplate.from_messages([(\"system\", qa_system_prompt), MessagesPlaceholder(\"chat_history\"), (\"human\", \"{input}\")])\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "    return create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37bc1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5: Assistant Tools and Features ---\n",
    "progress_tracker: Dict[str, str] = {}\n",
    "llm = None\n",
    "retriever = None\n",
    "all_documents_for_tools = []\n",
    "python_repl_tool = None\n",
    "rag_chain_for_tools = None\n",
    "\n",
    "@tool\n",
    "def curriculum_qa_tool(input: str, chat_history: List = []):\n",
    "    \"\"\"\n",
    "    Use this tool to answer any question about the content of the uploaded curriculum documents.\n",
    "    It is the primary tool for factual questions and information retrieval from the knowledge base.\n",
    "    For example: 'What is photosynthesis?', 'Summarize the section on data structures.'\n",
    "    \"\"\"\n",
    "    if rag_chain_for_tools is None: return \"RAG chain not initialized.\"\n",
    "    response = rag_chain_for_tools.invoke({\"input\": input, \"chat_history\": chat_history})\n",
    "    return response['answer']\n",
    "\n",
    "@tool\n",
    "def python_math_solver(problem: str):\n",
    "    \"\"\"\n",
    "    Use this specialized tool to solve mathematical problems, perform calculations, or answer word problems that require logic and computation.\n",
    "    It works by writing and executing Python code. For example: 'What is 24 * 5?', 'If a car travels at 80 km/h for 2.5 hours, how far does it go?'.\n",
    "    \"\"\"\n",
    "    if not llm or not python_repl_tool: return \"Math solver components not initialized.\"\n",
    "    print(f\"--- ðŸ Solving math problem with Python: '{problem}' ---\")\n",
    "    code_gen_prompt_text = (\n",
    "        \"You are an expert Python programmer tasked with solving a mathematical problem. \"\n",
    "        \"Based on the user's problem, write a single, executable block of Python code to find the solution. \"\n",
    "        \"IMPORTANT:\\n\"\n",
    "        \"- Only output the Python code. Do not include any explanation, comments, or markdown formatting like ```python. \"\n",
    "        \"- The code MUST print the final answer to the console using the print() function. \"\n",
    "        \"- You can use standard libraries like 'math'.\\n\\n\"\n",
    "        \"Problem: {problem}\"\n",
    "    )\n",
    "    code_gen_prompt = ChatPromptTemplate.from_template(code_gen_prompt_text)\n",
    "    code_gen_chain = code_gen_prompt | llm\n",
    "    code_to_execute = code_gen_chain.invoke({\"problem\": problem}).content\n",
    "    try:\n",
    "        result = python_repl_tool.run(code_to_execute)\n",
    "        return f\"Solution:\\n{result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error executing the Python code: {e}\"\n",
    "\n",
    "@tool\n",
    "def enhanced_quiz_generator(topic: str, num_questions: int = 3, question_type: str = \"multiple choice\"):\n",
    "    \"\"\"\n",
    "    Generates a quiz on a specific topic based on the curriculum. \n",
    "    Use this when the user explicitly asks for a quiz, test, or to check their knowledge.\n",
    "    Arguments: topic (str), num_questions (int, default 3), question_type (str, default 'multiple choice').\n",
    "    \"\"\"\n",
    "    if not retriever or not llm: return \"Retriever or LLM not initialized.\"\n",
    "    print(f\"--- â“ Generating a {num_questions}-question quiz on '{topic}'... ---\")\n",
    "    context_docs = retriever.invoke(topic)\n",
    "    context_text = \"\\n\\n\".join([doc.page_content for doc in context_docs])\n",
    "    if not context_text.strip(): return f\"Sorry, I couldn't find enough information on '{topic}' to create a quiz.\"\n",
    "    quiz_prompt_text = (\n",
    "        \"You are an expert quiz creator. Based ONLY on the provided context, create a quiz with {num_questions} \"\n",
    "        \"{question_type} questions about '{topic}'. For each multiple-choice question, provide 4 options (A, B, C, D) \"\n",
    "        \"and clearly mark the correct answer. For other question types, provide the question and the correct answer based on the text.\\n\\n\"\n",
    "        \"Context:\\n---\\n{context}\\n---\"\n",
    "    )\n",
    "    quiz_prompt = ChatPromptTemplate.from_template(quiz_prompt_text)\n",
    "    quiz_chain = quiz_prompt | llm\n",
    "    response = quiz_chain.invoke({\"num_questions\": num_questions, \"topic\": topic, \"question_type\": question_type, \"context\": context_text})\n",
    "    return response.content\n",
    "\n",
    "@tool\n",
    "def learning_path_suggester(topic: str):\n",
    "    \"\"\"\n",
    "    Suggests a step-by-step learning path for a given topic based on the provided documents.\n",
    "    Use this when the user asks 'How should I study for X?', 'What's the learning path for Y?', or 'Suggest a study plan.'\n",
    "    \"\"\"\n",
    "    if not llm: return \"LLM not initialized.\"\n",
    "    print(f\"--- ðŸ—ºï¸ Generating a learning path for '{topic}'... ---\")\n",
    "    full_context = \"\\n\\n\".join([doc.page_content for doc in all_documents_for_tools])\n",
    "    path_prompt_text = (\n",
    "        \"You are an expert academic advisor. Based on the entire curriculum provided, analyze the content related to '{topic}'. \"\n",
    "        \"Create a logical, step-by-step learning path for a student to master this topic. Break it down into key concepts, \"\n",
    "        \"suggesting the order in which they should be studied. Your output should be a clear, actionable list.\\n\\n\"\n",
    "        \"Full Curriculum Context:\\n---\\n{context}\\n---\"\n",
    "    )\n",
    "    path_prompt = ChatPromptTemplate.from_template(path_prompt_text)\n",
    "    path_chain = path_prompt | llm\n",
    "    response = path_chain.invoke({\"topic\": topic, \"context\": full_context})\n",
    "    return response.content\n",
    "\n",
    "@tool\n",
    "def mark_topic_as_studied(topic: str):\n",
    "    \"\"\"\n",
    "    Marks a topic as 'studied' in the progress tracker. Use this when a user says they have finished studying a topic.\n",
    "    \"\"\"\n",
    "    print(f\"--- âœ… Marking '{topic}' as studied. ---\")\n",
    "    progress_tracker[topic.lower()] = \"Studied\"\n",
    "    return f\"Great! I've marked '{topic}' as studied. Keep up the great work!\"\n",
    "\n",
    "@tool\n",
    "def view_study_progress(input: str = \"\"):\n",
    "    \"\"\"\n",
    "    Shows the user's study progress. Use this when the user asks 'What have I studied?' or 'Show my progress.'\n",
    "    This tool takes no arguments.\n",
    "    \"\"\"\n",
    "    print(\"--- ðŸ“Š Displaying study progress... ---\")\n",
    "    if not progress_tracker:\n",
    "        return \"You haven't marked any topics as studied yet.\"\n",
    "    progress_report = \"Here's your study progress so far:\\n\"\n",
    "    for topic, status in progress_tracker.items():\n",
    "        progress_report += f\"- {topic.capitalize()}: {status}\\n\"\n",
    "    return progress_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40cdf795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸš€ AI Curriculum Assistant Initializing (Agent Mode) ðŸš€ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_24812\\758033468.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aryan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "--- ðŸŽ¯ Processing specific file: DataStructures.pdf ---\n",
      "Processing PDF with PyPDFLoader: ./documents\\DataStructures.pdf\n",
      "Generating image summary...\n",
      "Generating image summary...\n",
      "Generating image summary...\n",
      "âœ… Successfully processed 621 chunks and summaries from ./documents\\DataStructures.pdf\n",
      "âœ… Loading existing vector store from './chroma_db'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_24812\\758033468.py:16: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=CHROMA_PERSIST_PATH, embedding_function=embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing cross-encoder for reranking: 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
      "\n",
      "âœ… Multi-tool Assistant is ready! Ask me a curriculum question or give me a math problem to solve.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Initialization and Main Execution ---\n",
    "print(\"--- ðŸš€ AI Curriculum Assistant Initializing (Agent Mode) ðŸš€ ---\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"âŒ Error: GOOGLE_API_KEY not found. Please set it in your .env file.\")\n",
    "else:\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "        llm = ChatGoogleGenerativeAI(model=LLM_MODEL, google_api_key=GOOGLE_API_KEY, temperature=0.5)\n",
    "        \n",
    "        # â¬‡ï¸ MODIFIED: Function call updated to the new single-file processor.\n",
    "        all_documents_for_tools = process_single_file(embeddings, llm)\n",
    "        if not all_documents_for_tools: raise ValueError(\"No documents were processed. Halting initialization.\")\n",
    "\n",
    "        if os.path.exists(CHROMA_PERSIST_PATH) and os.listdir(CHROMA_PERSIST_PATH):\n",
    "            print(f\"âœ… Loading existing vector store from '{CHROMA_PERSIST_PATH}'...\")\n",
    "            vectorstore = Chroma(persist_directory=CHROMA_PERSIST_PATH, embedding_function=embeddings)\n",
    "        else:\n",
    "            print(f\"âš ï¸ No existing vector store found. Creating and persisting a new one at '{CHROMA_PERSIST_PATH}'...\")\n",
    "            vectorstore = Chroma.from_documents(documents=all_documents_for_tools, embedding=embeddings, persist_directory=CHROMA_PERSIST_PATH)\n",
    "        \n",
    "        vector_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "        bm25_retriever = BM25Retriever.from_documents(all_documents_for_tools, k=10)\n",
    "        ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, vector_retriever], weights=[0.5, 0.5])\n",
    "        \n",
    "        print(f\"Initializing cross-encoder for reranking: '{CROSS_ENCODER_MODEL}'\")\n",
    "        model = HuggingFaceCrossEncoder(model_name=CROSS_ENCODER_MODEL)\n",
    "        compressor = CrossEncoderReranker(model=model, top_n=3)\n",
    "        retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)\n",
    "        \n",
    "        rag_chain_for_tools = create_rag_chain(retriever, llm)\n",
    "        python_repl_tool = PythonREPLTool()\n",
    "        \n",
    "        tools = [curriculum_qa_tool, python_math_solver, enhanced_quiz_generator, learning_path_suggester, mark_topic_as_studied, view_study_progress]\n",
    "        \n",
    "        agent_prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "        agent = create_react_agent(llm, tools, agent_prompt)\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "        \n",
    "        chat_history = []\n",
    "        print(\"\\nâœ… Multi-tool Assistant is ready! Ask me a curriculum question or give me a math problem to solve.\")\n",
    "        \n",
    "    except (ValueError, FileNotFoundError) as e: print(f\"âŒ Error: {e}\")\n",
    "    except Exception as e: print(f\"âŒ An unexpected error occurred during initialization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b81750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```tool_code\n",
      "Thought: Do I need to use a tool? No\n",
      "Final Answer: Here's the C code for a Bubble Sort algorithm:\n",
      "\n",
      "```c\n",
      "#include <stdio.h>\n",
      "\n",
      "void bubbleSort(int arr[], int n) {\n",
      "  int i, j;\n",
      "  for (i = 0; i < n - 1; i++) {\n",
      "    for (j = 0; j < n - i - 1; j++) {\n",
      "      if (arr[j] > arr[j + 1]) {\n",
      "        // Swap arr[j] and arr[j+1]\n",
      "        int temp = arr[j];\n",
      "        arr[j] = arr[j + 1];\n",
      "        arr[j + 1] = temp;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "void printArray(int arr[], int n) {\n",
      "  int i;\n",
      "  for (i = 0; i < n; i++)\n",
      "    printf(\"%d \", arr[i]);\n",
      "  printf(\"\\n\");\n",
      "}\n",
      "\n",
      "int main() {\n",
      "  int arr[] = {64, 34, 25, 12, 22, 11, 90};\n",
      "  int n = sizeof(arr) / sizeof(arr[0]);\n",
      "  bubbleSort(arr, n);\n",
      "  printf(\"Sorted array: \\n\");\n",
      "  printArray(arr, n);\n",
      "  return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "This code first defines a `bubbleSort` function that takes an integer array `arr` and its size `n` as input.  It uses nested loops to iterate through the array, comparing adjacent elements and swapping them if they are in the wrong order. The outer loop iterates `n-1` times, and the inner loop iterates `n-i-1` times in each iteration of the outer loop. This optimization avoids unnecessary comparisons in later iterations.\n",
      "\n",
      "The `printArray` function is a helper function to display the sorted array. The `main` function demonstrates how to use the `bubbleSort` function with a sample array.  Remember to compile this code using a C compiler (like GCC) before running it.\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ðŸ¤– Assistant: Here's the C code for a Bubble Sort algorithm:\n",
      "\n",
      "```c\n",
      "#include <stdio.h>\n",
      "\n",
      "void bubbleSort(int arr[], int n) {\n",
      "  int i, j;\n",
      "  for (i = 0; i < n - 1; i++) {\n",
      "    for (j = 0; j < n - i - 1; j++) {\n",
      "      if (arr[j] > arr[j + 1]) {\n",
      "        // Swap arr[j] and arr[j+1]\n",
      "        int temp = arr[j];\n",
      "        arr[j] = arr[j + 1];\n",
      "        arr[j + 1] = temp;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "void printArray(int arr[], int n) {\n",
      "  int i;\n",
      "  for (i = 0; i < n; i++)\n",
      "    printf(\"%d \", arr[i]);\n",
      "  printf(\"\\n\");\n",
      "}\n",
      "\n",
      "int main() {\n",
      "  int arr[] = {64, 34, 25, 12, 22, 11, 90};\n",
      "  int n = sizeof(arr) / sizeof(arr[0]);\n",
      "  bubbleSort(arr, n);\n",
      "  printf(\"Sorted array: \\n\");\n",
      "  printArray(arr, n);\n",
      "  return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "This code first defines a `bubbleSort` function that takes an integer array `arr` and its size `n` as input.  It uses nested loops to iterate through the array, comparing adjacent elements and swapping them if they are in the wrong order. The outer loop iterates `n-1` times, and the inner loop iterates `n-i-1` times in each iteration of the outer loop. This optimization avoids unnecessary comparisons in later iterations.\n",
      "\n",
      "The `printArray` function is a helper function to display the sorted array. The `main` function demonstrates how to use the `bubbleSort` function with a sample array.  Remember to compile this code using a C compiler (like GCC) before running it.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#Cell 7: Interactive Chat Loop ---\n",
    "if 'agent_executor' in locals():\n",
    "    user_input = \"Give C Code for Bubble Sort\"\n",
    "    \n",
    "    response = agent_executor.invoke({\n",
    "        \"input\": user_input,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    \n",
    "    answer = response[\"output\"]\n",
    "    print(f\"ðŸ¤– Assistant: {answer}\")\n",
    "    \n",
    "    chat_history.extend([\n",
    "        HumanMessage(content=user_input),\n",
    "        AIMessage(content=answer),\n",
    "    ])\n",
    "else:\n",
    "    print(\"The Agent Executor is not initialized. Please run the setup cells successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
